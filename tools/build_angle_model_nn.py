#!/usr/bin/env python3
"""
Usage:
  python build_angle_model.py <shot_data.json> --output model.js

Trains an MLP regression model to predict angleError from:
  - cutAngle, power        (spinY kept for signature compatibility, ignored)

Outputs a self-contained JavaScript file exporting:
  - predictAngleError(cutAngle, spinY, power)
  - calculateAimAdjustment(cutAngle, spinY, power)
  - ANGLE_MODEL_INFO
"""

from __future__ import annotations

import argparse
import json
import math
from pathlib import Path
from typing import List, Any, Tuple

import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPRegressor
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score


# IMPORTANT: only cutAngle and power used
FEATURES = ["cutAngle", "power"]
TARGET = "angleError"


def _fmt(x: float) -> str:
    if abs(x) < 1e-12:
        x = 0.0
    return f"{float(x):.12g}"


def _js_array(obj: Any, indent: int = 0) -> str:
    sp = " " * indent
    if isinstance(obj, list):
        if len(obj) == 0:
            return "[]"
        if isinstance(obj[0], list):
            inner = ",\n".join(sp + "  " + _js_array(x, indent + 2) for x in obj)
            return "[\n" + inner + "\n" + sp + "]"
        return "[" + ", ".join(_fmt(float(x)) for x in obj) + "]"
    raise TypeError(f"Unsupported type for js export: {type(obj)}")


def build_js(
    data_name: str,
    mean: List[float],
    scale: List[float],
    W: List[List[List[float]]],
    b: List[List[float]],
    hidden_layers: Tuple[int, ...],
    activation: str,
    n_samples: int,
    r2: float,
    rmse: float,
    mae: float,
    seed: int,
) -> str:
    # Generic forward-pass for arbitrary layer sizes
    # Uses Math.max(0,z) for relu; Math.tanh(z) for tanh
    return f"""\
/* eslint-disable no-var, prefer-const */
/**
 * Auto-generated angle error model.
 *
 * Trained on: {data_name}
 * Features used: cutAngle, power (spinY ignored)
 * Network: 2 -> {list(hidden_layers)} -> 1
 * Activation: {activation}
 * Metrics (holdout test):
 *   rSquared: {r2:.6f}
 *   rmse: {rmse:.6f}
 *   mae: {mae:.6f}
 *
 * Generated by build_angle_model.py
 */

// Feature order: ['cutAngle','power']
const __ANGLE_SCALER_MEAN = {_js_array(mean)};
const __ANGLE_SCALER_SCALE = {_js_array(scale)};

// MLP weights (sklearn-style: coefs_ and intercepts_)
const __ANGLE_W = {_js_array(W)};
const __ANGLE_B = {_js_array(b)};

function __act(z) {{
  {"return Math.max(0, z);" if activation == "relu" else "return Math.tanh(z);"}
}}

function __matvec(x, W, b, applyAct) {{
  const outDim = b.length;
  const inDim = x.length;
  const y = new Array(outDim);
  for (let j = 0; j < outDim; j++) {{
    let s = b[j];
    for (let i = 0; i < inDim; i++) s += x[i] * W[i][j];
    y[j] = applyAct ? __act(s) : s;
  }}
  return y;
}}

/**
 * Predict the angle error for a shot
 * @param {{number}} cutAngle
 * @param {{number}} spinY   - ignored (kept for compatibility)
 * @param {{number}} power
 * @returns {{number}} predicted angleError in degrees
 */
function predictAngleError(cutAngle, spinY, power) {{
  if (!Number.isFinite(cutAngle) || !Number.isFinite(power)) return 0;

  // normalize inputs
  const x0 = (cutAngle - __ANGLE_SCALER_MEAN[0]) / __ANGLE_SCALER_SCALE[0];
  const x1 = (power   - __ANGLE_SCALER_MEAN[1]) / __ANGLE_SCALER_SCALE[1];
  let x = [x0, x1];

  // hidden layers
  for (let L = 0; L < __ANGLE_W.length - 1; L++) {{
    x = __matvec(x, __ANGLE_W[L], __ANGLE_B[L], true);
  }}

  // output layer (linear)
  const last = __ANGLE_W.length - 1;
  const y = __matvec(x, __ANGLE_W[last], __ANGLE_B[last], false)[0];

  return y;
}}

function calculateAimAdjustment(cutAngle, spinY, power) {{
  return predictAngleError(cutAngle, spinY, power);
}}

const ANGLE_MODEL_INFO = {{
  modelType: "mlp_regression",
  nSamples: {n_samples},
  featuresUsed: ["cutAngle", "power"],
  signature: ["cutAngle", "spinY (ignored)", "power"],
  network: {{
    layers: [2, ...{list(hidden_layers)}, 1],
    activation: "{activation}",
    solver: "adam",
    seed: {seed}
  }},
  metrics: {{
    rSquared: {r2:.6f},
    rmse: {rmse:.6f},
    mae: {mae:.6f}
  }}
}};

if (typeof module !== "undefined" && module.exports) {{
  module.exports = {{ predictAngleError, calculateAimAdjustment, ANGLE_MODEL_INFO }};
}}
"""


def main() -> None:
    ap = argparse.ArgumentParser()
    ap.add_argument("shot_data", type=str)
    ap.add_argument("--output", type=str, default="model.js")
    ap.add_argument("--seed", type=int, default=42)
    ap.add_argument("--restarts", type=int, default=8, help="train N times and keep best validation RMSE")
    ap.add_argument("--test_size", type=float, default=0.2)
    ap.add_argument("--val_size", type=float, default=0.2, help="validation split from train (early_stopping uses this)")
    args = ap.parse_args()

    data_path = Path(args.shot_data)
    raw = json.loads(data_path.read_text())

    X = np.array([[row[f] for f in FEATURES] for row in raw], dtype=np.float64)
    y = np.array([row[TARGET] for row in raw], dtype=np.float64)

    # holdout test set for final metrics
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=args.test_size, random_state=args.seed
    )

    # A stronger default architecture for stepped/piecewise-ish patterns
    hidden = (64, 64, 32)
    activation = "relu"

    best_pipe = None
    best_val = float("inf")
    best_seed = None

    for k in range(args.restarts):
        seed_k = args.seed + k

        pipe = Pipeline(
            steps=[
                ("scaler", StandardScaler()),
                ("mlp", MLPRegressor(
                    hidden_layer_sizes=hidden,
                    activation=activation,      # relu learns sharp-ish transitions better than tanh
                    solver="adam",
                    alpha=1e-6,                 # lighter L2 so it can fit banding
                    learning_rate_init=3e-3,    # faster learning
                    max_iter=20000,
                    early_stopping=True,
                    validation_fraction=args.val_size,
                    n_iter_no_change=200,
                    tol=1e-6,
                    random_state=seed_k,
                )),
            ]
        )

        pipe.fit(X_train, y_train)

        # use the internal best_validation_score_ if available, otherwise compute quick val
        mlp: MLPRegressor = pipe.named_steps["mlp"]
        # sklearn stores best validation score as R^2, so we compute our own val RMSE via split:
        X_tr, X_val, y_tr, y_val = train_test_split(X_train, y_train, test_size=args.val_size, random_state=seed_k)
        pipe.fit(X_tr, y_tr)
        pred_val = pipe.predict(X_val)
        val_rmse = math.sqrt(mean_squared_error(y_val, pred_val))

        if val_rmse < best_val:
            best_val = val_rmse
            best_pipe = pipe
            best_seed = seed_k

    assert best_pipe is not None

    # Final test metrics
    pred = best_pipe.predict(X_test)
    mae = mean_absolute_error(y_test, pred)
    rmse = math.sqrt(mean_squared_error(y_test, pred))
    r2 = r2_score(y_test, pred)

    scaler: StandardScaler = best_pipe.named_steps["scaler"]
    mlp: MLPRegressor = best_pipe.named_steps["mlp"]

    mean = scaler.mean_.tolist()
    scale = scaler.scale_.tolist()
    W = [w.tolist() for w in mlp.coefs_]
    b = [bb.tolist() for bb in mlp.intercepts_]

    out_js = build_js(
        data_name=data_path.name,
        mean=mean,
        scale=scale,
        W=W,
        b=b,
        hidden_layers=hidden,
        activation=activation,
        n_samples=len(raw),
        r2=r2,
        rmse=rmse,
        mae=mae,
        seed=int(best_seed),
    )

    out_path = Path(args.output)
    out_path.write_text(out_js, encoding="utf-8")

    print("Wrote:", out_path)
    print(f"Best validation RMSE across restarts: {best_val:.6f}")
    print(f"Test metrics: r2={r2:.6f}, rmse={rmse:.6f}, mae={mae:.6f}")
    print(f"Chosen seed: {best_seed}")


if __name__ == "__main__":
    main()
